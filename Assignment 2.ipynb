{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Marie Howell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:\n",
      "(4600, 57)\n",
      "\n",
      "Shape of y:\n",
      "(4600,)\n",
      "\n",
      "Type of x:\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "\n",
      "Type of y:\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "X, y = load_spam()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Shape of x:\")\n",
    "print(X.shape)\n",
    "print(\"\\nShape of y:\")\n",
    "print(y.shape)\n",
    "\n",
    "print(\"\\nType of x:\")\n",
    "print(X.dtypes) \n",
    "print(\"\\nType of y:\")\n",
    "print(y.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values in X: \n",
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      "\n",
      "Checking for null values in y: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"Checking for null values in X: \")\n",
    "print(X.isnull().sum())\n",
    "print(\"\\nChecking for null values in y: \")\n",
    "print(y.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_small, _, y_small, _= train_test_split(X,y, train_size=0.05, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Size</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(4600, 57)</td>\n",
       "      <td>0.927717</td>\n",
       "      <td>0.936957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(4600, 2)</td>\n",
       "      <td>0.614946</td>\n",
       "      <td>0.593478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(230, 57)</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data Size  Training accuracy  Validation accuracy\n",
       "0  (4600, 57)           0.927717             0.936957\n",
       "1   (4600, 2)           0.614946             0.593478\n",
       "2   (230, 57)           0.934783             0.869565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# using X and y \n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "data_accuracy = np.array([[model.score(X_train, y_train), model.score(X_test, y_test)]])\n",
    "\n",
    "# using only the first two columns of X and y\n",
    "\n",
    "X2 = X[['word_freq_make', 'word_freq_address']]\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X2,y, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "data_accuracy = np.append(data_accuracy,[[model.score(X_train, y_train), model.score(X_test, y_test)]], axis=0)\n",
    "\n",
    "\n",
    "# using X_small and y_small\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_small,y_small, test_size=0.2, random_state=0)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "data_accuracy = np.append(data_accuracy,[[model.score(X_train, y_train), model.score(X_test, y_test)]], axis=0)\n",
    "\n",
    "# creating data frame \n",
    "results = pd.DataFrame(data_accuracy, columns=[\"Training accuracy\", \"Validation accuracy\"])\n",
    "\n",
    "data_size = [X.shape, X2.shape, X_small.shape]\n",
    "\n",
    "results.insert(0, \"Data Size\", data_size, True)\n",
    "\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "\n",
    "Case 1: All the data is used \n",
    "\n",
    "The training score is relatively close to 1 which on its own is an attribute of a well-fitting model. But when compared against the validation score, we see that the two values are very close and the validation score is slightly higher. Based off the validation curve discussed in class this seems like a peculiar outcome. The ideal situation is to have both values high and relatively close to one another so based on this you could say that this is a well-fitting model, however before concluding this I would want to see how the model performs on other unseen data. \n",
    "\n",
    "\n",
    "Case 2: Only the first two columns \n",
    "\n",
    "In this case our training score is low indicating low accuracy of the model. The training and validation score are also very close in value which indicates that the model has high bias and is underfitting the data. Reducing the number of column’s considered did not improve the model. This means that the two columns used are not predictive of if an email is spam or not spam on their own. \n",
    "\n",
    "\n",
    "Case 3: 5% of the data \n",
    "\n",
    "In this case the training value is close to one and even a little higher than in the first case. The validation score is lower than in the first case which may indicate that the peak of the validation curve has been passed. If this is the case the model would be overfitting the data. \n",
    "\n",
    "\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "Since we are looking for emails that would be classified as spam the positive class would be spam emails and the negative class would be non-spam emails.  Emails being classified as spam when they are not would be a false positive and spam emails not being classified as spam would be a false negative. Regular emails being classified as spam when they aren’t could prevent users from receiving important emails, so I would say false positives are worse in this scenario. That being said, spam emails can be potentially harmful so which is worse is very dependant on the priorities of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "I based my code off the lecture examples and the lab content. When there were small concepts, I needed a refresher on (like data frames) I just googled it and looked through websites until I collected enough info to understand the concept.  Initially I tried to immediately start writing code with the lab exercises as my guidance but very soon I realized I need to have a better understanding of the concepts behind what I was trying to do. I went back and read through the lecture slides and took some notes on the key concepts. Then I went through the examples and made sure I understood what was being done in the examples. From there it was relatively easy to write the code required to complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:\n",
      "(1030, 8)\n",
      "\n",
      "Shape of y:\n",
      "(1030,)\n",
      "\n",
      "Type of x:\n",
      "cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "\n",
      "Type of y:\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X_concrete, y_concrete = load_concrete()\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Shape of x:\")\n",
    "print(X_concrete.shape)\n",
    "print(\"\\nShape of y:\")\n",
    "print(y_concrete.shape)\n",
    "\n",
    "print(\"\\nType of x:\")\n",
    "print(X_concrete.dtypes) \n",
    "print(\"\\nType of y:\")\n",
    "print(y_concrete.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values in X: \n",
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "\n",
      "Checking for null values in y: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"Checking for null values in X: \")\n",
    "print(X_concrete.isnull().sum())\n",
    "print(\"\\nChecking for null values in y: \")\n",
    "print(y_concrete.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_concrete ,y_concrete,test_size=0.2, random_state=0)\n",
    "\n",
    "lr =LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score: 0.61\n",
      "Validation R2 score: 0.64\n",
      "\n",
      "Training Mean Squared Erorr: 110.35\n",
      "Validation Mean Squared Error : 95.64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val,y_val_pred)\n",
    "\n",
    "print(\"Training R2 score: {:.2f}\".format(r2_train))\n",
    "print(\"Validation R2 score: {:.2f}\".format(r2_val))\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val,y_val_pred)\n",
    "\n",
    "print(\"\\nTraining Mean Squared Erorr: {:.2f}\".format(mse_train))\n",
    "print(\"Validation Mean Squared Error : {:.2f}\".format(mse_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Training accuracy  Validation accuracy\n",
       "Metric                                        \n",
       "R2               0.609071             0.636898\n",
       "MSE            110.345501            95.635335"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame({'Metric' : ['R2','MSE'], 'Training accuracy' : [r2_train, mse_train],'Validation accuracy' : [r2_val, mse_val]})\n",
    "\n",
    "results.set_index('Metric', inplace=True)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "Based on the scores calculated the linear model did not produce good quality results. The training R2 value is low which indicates that the model is not predicting variability in the target vector very effectively. The validation R2 value is very close to the training R2 value which indicates high bias and that the model is underfitting the data. More flexibility is required in the model to capture the underlying patterns in the data. Both mean squared error values were very high for the given data set, indicating that the model was not able to learn or predict the patterns in the data effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "I used pretty much the same process as in the first part of the assignment. When I started on the second part of the assignment, I had already done a thorough review of the lecture content so it went much quicker than the first half. I was also able to use the code from the first part and just adjust it to fit the specifications of the second part. When it came to interpreting the values, I needed to do a little more reading on MSE and R2 values to ensure I fully understood what they represented and what their value says about the model. I googled the two concepts and did a little reading until I felt I had a firm grasp on the concepts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "In Part 1 we saw the effect of the size of the data on the model. Using the whole data set produced a training accuracy and validation accuracy of 0.93 and 0.94, using only the first two columns produced values of 0.61 and 0.59, and using only five percent of the data set produced values of 0.93 and 0.87. The model with the poorest performance was when only two columns of data were used, the model turned out to have a high bias and under fit the data. This showed that for this data set the additional columns were necessary to capture the full view of the underlying patterns in the data. The results for the whole data set were a little difficult to interpret, the values reflect very high accuracy but could be too close together. The validation accuracy turned out to be higher than the training accuracy which may be an indication that the training data and testing data may be too similar. Overall, the best performance seemed to be the model using only five precent of the data set, both values are reasonably high which is an indication of a well-fitting model. \n",
    "\n",
    "In part 2 we saw a data set that was too complex to be adequately described by a linear model. The training accuracy and the validation accuracy were 0.61 and 0.64 respectively. These values are low and close together indicating that the model has high bias and is underfitting the data set. This tells us that we need to increase the model’s complexity to able to describe the data well. The linear regression model was not able to capture the under lying trends in the data set. The error values for the model were also very high. The maximum value for compressive strength in the target vector y_concrete was 82.60 MPa and the mean squared error value for the training set was 110.34 MPa. This means that the error was greater than the largest value in the set indicating that percent error values are roughly 100%.  The results for the mean squared error also reflect a poor fitting model In the bonus question we were able to see that ridge and lasso regression were also unable to produce an adequately fitting model, even with the ability to tune the hyperparameter alpha.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "I liked getting the chance to go through the ML work flow myself, I think it helped me solidify the concepts we’ve been going over in class. I would have liked to apply a linear model to a data set that fit the linear model better to see what that looks like for myself.  \n",
    "\n",
    "At first, I found it confusing trying to figure out how to calculate and interpret the different values related to the different models. But after reviewing the class notes and the examples on d2l I was able to understand the assignment better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression with alpha = 0.001\n",
      " Training score: 0.61\n",
      " Validation score: 0.63\n",
      "\n",
      "Ridge Regression with alpha = 100\n",
      " Training score: 0.61\n",
      " Validation score: 0.63\n",
      "\n",
      "Lasso Regression with alpha = 0.001\n",
      "Training set score: 0.61\n",
      "Validation set score: 0.63\n",
      "\n",
      "Lasso Regression with alpha = 100\n",
      "Training set score: 0.47\n",
      "Validation set score: 0.44\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Ridge Regression \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_concrete, y_concrete = load_concrete()\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_concrete ,y_concrete,test_size=0.2, random_state=42)\n",
    "ridge001 = Ridge(alpha=0.001).fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge Regression with alpha = 0.001\")\n",
    "print(\" Training score: {:.2f}\".format(ridge001.score(X_train, y_train)))\n",
    "print(\" Validation score: {:.2f}\".format(ridge001.score(X_val, y_val)))\n",
    "\n",
    "ridge100 = Ridge(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRidge Regression with alpha = 100\")\n",
    "print(\" Training score: {:.2f}\".format(ridge100.score(X_train, y_train)))\n",
    "print(\" Validation score: {:.2f}\".format(ridge100.score(X_val, y_val)))\n",
    "\n",
    "#Lasso Regression \n",
    "lasso001 = Lasso(alpha=0.001).fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nLasso Regression with alpha = 0.001\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso001.score(X_val, y_val)))\n",
    "\n",
    "lasso100 = Lasso(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nLasso Regression with alpha = 100\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso100.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso100.score(X_val, y_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "Ridge Regression \n",
    "\n",
    "Changing alpha from 0.001 to 100 had no effect on the accuracy scores. This means that both lowering and raising the regularization of the model made no improvement. \n",
    "\n",
    "Lasso Regression \n",
    "\n",
    "Lowering alpha had no effect on the accuracy scores, while raising alpha decreased the accuracy scores. This means that lowering the regularization of the model had no effect and raising the regularization made the model more inaccurate. Increasing regularization strength forces the model to simplify and generalize, the fact that further regularization had a negative effect on the model indicates that this model is not complex enough to capture the patterns in the data. \n",
    "\n",
    "Conclusion \n",
    "\n",
    "None of the linear models were able to effectively fit this data set. Even with the ability to tune the hyperparameter alpha in the Ridge and Lasso regression models did not yield better results. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
